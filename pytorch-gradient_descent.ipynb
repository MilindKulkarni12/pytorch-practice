{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "tensor([2., 4., 6., 8.])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "print(X)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss(y, y_pred):\n",
    "    return  ((y - y_pred)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., requires_grad=True) 0.01 50\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "alpha = 0.01\n",
    "iterations = 50\n",
    "print(w, alpha, iterations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MulBackward0>)\n",
      "0, w: 0.300, loss: 30.000000\n",
      "1, w: 0.555, loss: 21.674999\n",
      "2, w: 0.772, loss: 15.660188\n",
      "3, w: 0.956, loss: 11.314487\n",
      "4, w: 1.113, loss: 8.174717\n",
      "5, w: 1.246, loss: 5.906232\n",
      "6, w: 1.359, loss: 4.267253\n",
      "7, w: 1.455, loss: 3.083090\n",
      "8, w: 1.537, loss: 2.227532\n",
      "9, w: 1.606, loss: 1.609392\n",
      "10, w: 1.665, loss: 1.162786\n",
      "11, w: 1.716, loss: 0.840112\n",
      "12, w: 1.758, loss: 0.606981\n",
      "13, w: 1.794, loss: 0.438544\n",
      "14, w: 1.825, loss: 0.316848\n",
      "15, w: 1.851, loss: 0.228923\n",
      "16, w: 1.874, loss: 0.165397\n",
      "17, w: 1.893, loss: 0.119499\n",
      "18, w: 1.909, loss: 0.086338\n",
      "19, w: 1.922, loss: 0.062379\n",
      "20, w: 1.934, loss: 0.045069\n",
      "21, w: 1.944, loss: 0.032562\n",
      "22, w: 1.952, loss: 0.023526\n",
      "23, w: 1.960, loss: 0.016998\n",
      "24, w: 1.966, loss: 0.012281\n",
      "25, w: 1.971, loss: 0.008873\n",
      "26, w: 1.975, loss: 0.006411\n",
      "27, w: 1.979, loss: 0.004632\n",
      "28, w: 1.982, loss: 0.003346\n",
      "29, w: 1.985, loss: 0.002418\n",
      "30, w: 1.987, loss: 0.001747\n",
      "31, w: 1.989, loss: 0.001262\n",
      "32, w: 1.991, loss: 0.000912\n",
      "33, w: 1.992, loss: 0.000659\n",
      "34, w: 1.993, loss: 0.000476\n",
      "35, w: 1.994, loss: 0.000344\n",
      "36, w: 1.995, loss: 0.000248\n",
      "37, w: 1.996, loss: 0.000180\n",
      "38, w: 1.996, loss: 0.000130\n",
      "39, w: 1.997, loss: 0.000094\n",
      "40, w: 1.997, loss: 0.000068\n",
      "41, w: 1.998, loss: 0.000049\n",
      "42, w: 1.998, loss: 0.000035\n",
      "43, w: 1.998, loss: 0.000026\n",
      "44, w: 1.999, loss: 0.000018\n",
      "45, w: 1.999, loss: 0.000013\n",
      "46, w: 1.999, loss: 0.000010\n",
      "47, w: 1.999, loss: 0.000007\n",
      "48, w: 1.999, loss: 0.000005\n",
      "49, w: 1.999, loss: 0.000004\n",
      "tensor(9.9970, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(forward(5))\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # predict\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # calculate loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradient descent => backward pass in pytorch\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= alpha * w.grad\n",
    "\n",
    "    # reset gradients\n",
    "    w.grad.zero_()\n",
    "    print(f\"{_}, w: {w:.3f}, loss: {l:5f}\")\n",
    "\n",
    "print(forward(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Descent using PyTorch Neural Network Module"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Type 1: Use optimizer for loss function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "tensor([2., 4., 6., 8.])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "print(X)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., requires_grad=True) 0.01 50\n",
      "MSELoss() SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "alpha = 0.01\n",
    "iterations = 50\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=alpha)\n",
    "print(w, alpha, iterations)\n",
    "print(loss, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MulBackward0>)\n",
      "0, w: 0.300, loss: 30.000000\n",
      "1, w: 0.555, loss: 21.674999\n",
      "2, w: 0.772, loss: 15.660188\n",
      "3, w: 0.956, loss: 11.314487\n",
      "4, w: 1.113, loss: 8.174717\n",
      "5, w: 1.246, loss: 5.906232\n",
      "6, w: 1.359, loss: 4.267253\n",
      "7, w: 1.455, loss: 3.083090\n",
      "8, w: 1.537, loss: 2.227532\n",
      "9, w: 1.606, loss: 1.609392\n",
      "10, w: 1.665, loss: 1.162786\n",
      "11, w: 1.716, loss: 0.840112\n",
      "12, w: 1.758, loss: 0.606981\n",
      "13, w: 1.794, loss: 0.438544\n",
      "14, w: 1.825, loss: 0.316848\n",
      "15, w: 1.851, loss: 0.228923\n",
      "16, w: 1.874, loss: 0.165397\n",
      "17, w: 1.893, loss: 0.119499\n",
      "18, w: 1.909, loss: 0.086338\n",
      "19, w: 1.922, loss: 0.062379\n",
      "20, w: 1.934, loss: 0.045069\n",
      "21, w: 1.944, loss: 0.032562\n",
      "22, w: 1.952, loss: 0.023526\n",
      "23, w: 1.960, loss: 0.016998\n",
      "24, w: 1.966, loss: 0.012281\n",
      "25, w: 1.971, loss: 0.008873\n",
      "26, w: 1.975, loss: 0.006411\n",
      "27, w: 1.979, loss: 0.004632\n",
      "28, w: 1.982, loss: 0.003346\n",
      "29, w: 1.985, loss: 0.002418\n",
      "30, w: 1.987, loss: 0.001747\n",
      "31, w: 1.989, loss: 0.001262\n",
      "32, w: 1.991, loss: 0.000912\n",
      "33, w: 1.992, loss: 0.000659\n",
      "34, w: 1.993, loss: 0.000476\n",
      "35, w: 1.994, loss: 0.000344\n",
      "36, w: 1.995, loss: 0.000248\n",
      "37, w: 1.996, loss: 0.000180\n",
      "38, w: 1.996, loss: 0.000130\n",
      "39, w: 1.997, loss: 0.000094\n",
      "40, w: 1.997, loss: 0.000068\n",
      "41, w: 1.998, loss: 0.000049\n",
      "42, w: 1.998, loss: 0.000035\n",
      "43, w: 1.998, loss: 0.000026\n",
      "44, w: 1.999, loss: 0.000018\n",
      "45, w: 1.999, loss: 0.000013\n",
      "46, w: 1.999, loss: 0.000010\n",
      "47, w: 1.999, loss: 0.000007\n",
      "48, w: 1.999, loss: 0.000005\n",
      "49, w: 1.999, loss: 0.000004\n",
      "tensor(9.9970, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(forward(5))\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # predict\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # calculate loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradient descent => backward pass in pytorch\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # reset gradients\n",
    "    w.grad.zero_()\n",
    "    print(f\"{_}, w: {w:.3f}, loss: {l:5f}\")\n",
    "\n",
    "print(forward(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Type 2: Use PyTorch Neural Networks Module for model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]]) torch.Size([4, 1])\n",
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [6.],\n",
      "        [8.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "print(X, X.shape)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "print(X_test, X_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "input_size, output_size = n_features, n_features\n",
    "model = nn.Linear(input_size, output_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., requires_grad=True) 0.01 100\n",
      "MSELoss() SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "alpha = 0.01\n",
    "iterations = 100\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=alpha)\n",
    "print(w, alpha, iterations)\n",
    "print(loss, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5552608966827393\n",
      "0, w: 0.840, loss: 18.124456\n",
      "1, w: 1.267, loss: 12.576178\n",
      "2, w: 1.817, loss: 5.031259\n",
      "3, w: 2.397, loss: 0.319455\n",
      "4, w: 2.912, loss: 1.456946\n",
      "5, w: 3.274, loss: 7.715586\n",
      "6, w: 3.424, loss: 15.089011\n",
      "7, w: 3.337, loss: 18.857248\n",
      "8, w: 3.026, loss: 16.608120\n",
      "9, w: 2.544, loss: 9.781373\n",
      "10, w: 1.972, loss: 2.747030\n",
      "11, w: 1.405, loss: 0.008011\n",
      "12, w: 0.937, loss: 3.317653\n",
      "13, w: 0.647, loss: 10.557344\n",
      "14, w: 0.583, loss: 17.092716\n",
      "15, w: 0.756, loss: 18.740261\n",
      "16, w: 1.137, loss: 14.445328\n",
      "17, w: 1.662, loss: 6.957249\n",
      "18, w: 2.244, loss: 1.069390\n",
      "19, w: 2.785, loss: 0.550769\n",
      "20, w: 3.195, loss: 5.733370\n",
      "21, w: 3.406, loss: 13.299642\n",
      "22, w: 3.382, loss: 18.406155\n",
      "23, w: 3.127, loss: 17.784061\n",
      "24, w: 2.684, loss: 11.831589\n",
      "25, w: 2.127, loss: 4.359107\n",
      "26, w: 1.549, loss: 0.150005\n",
      "27, w: 1.046, loss: 1.898667\n",
      "28, w: 0.702, loss: 8.485716\n",
      "29, w: 0.575, loss: 15.694564\n",
      "30, w: 0.686, loss: 18.910585\n",
      "31, w: 1.017, loss: 16.075100\n",
      "32, w: 1.511, loss: 9.003195\n",
      "33, w: 2.087, loss: 2.221831\n",
      "34, w: 2.649, loss: 0.071989\n",
      "35, w: 3.102, loss: 3.929853\n",
      "36, w: 3.371, loss: 11.325877\n",
      "37, w: 3.411, loss: 17.525616\n",
      "38, w: 3.215, loss: 18.560411\n",
      "39, w: 2.816, loss: 13.767859\n",
      "40, w: 2.280, loss: 6.215830\n",
      "41, w: 1.698, loss: 0.738628\n",
      "42, w: 1.166, loss: 0.842395\n",
      "43, w: 0.773, loss: 6.460705\n",
      "44, w: 0.585, loss: 13.997091\n",
      "45, w: 0.632, loss: 18.627262\n",
      "46, w: 0.908, loss: 17.387289\n",
      "47, w: 1.366, loss: 11.070923\n",
      "48, w: 1.930, loss: 3.721479\n",
      "49, w: 2.505, loss: 0.043581\n",
      "50, w: 2.995, loss: 2.391575\n",
      "51, w: 3.319, loss: 9.262432\n",
      "52, w: 3.423, loss: 16.257883\n",
      "53, w: 3.288, loss: 18.899916\n",
      "54, w: 2.938, loss: 15.497267\n",
      "55, w: 2.431, loss: 8.228096\n",
      "56, w: 1.852, loss: 1.745631\n",
      "57, w: 1.297, loss: 0.199522\n",
      "58, w: 0.859, loss: 4.579481\n",
      "59, w: 0.612, loss: 12.081752\n",
      "60, w: 0.596, loss: 17.903879\n",
      "61, w: 0.814, loss: 18.318928\n",
      "62, w: 1.230, loss: 13.061209\n",
      "63, w: 1.774, loss: 5.496365\n",
      "64, w: 2.356, loss: 0.466903\n",
      "65, w: 2.878, loss: 1.192352\n",
      "66, w: 3.253, loss: 7.208325\n",
      "67, w: 3.419, loss: 14.663802\n",
      "68, w: 3.347, loss: 18.786278\n",
      "69, w: 3.050, loss: 16.936819\n",
      "70, w: 2.578, loss: 10.299330\n",
      "71, w: 2.009, loss: 3.122684\n",
      "72, w: 1.438, loss: 0.000893\n",
      "73, w: 0.961, loss: 2.932320\n",
      "74, w: 0.657, loss: 10.040460\n",
      "75, w: 0.578, loss: 16.775156\n",
      "76, w: 0.735, loss: 18.825306\n",
      "77, w: 1.104, loss: 14.878538\n",
      "78, w: 1.623, loss: 7.461311\n",
      "79, w: 2.204, loss: 1.321640\n",
      "80, w: 2.751, loss: 0.389730\n",
      "81, w: 3.173, loss: 5.262130\n",
      "82, w: 3.398, loss: 12.819856\n",
      "83, w: 3.391, loss: 18.224953\n",
      "84, w: 3.150, loss: 18.017439\n",
      "85, w: 2.718, loss: 12.330150\n",
      "86, w: 2.166, loss: 4.803712\n",
      "87, w: 1.586, loss: 0.256046\n",
      "88, w: 1.075, loss: 1.598263\n",
      "89, w: 0.719, loss: 7.971170\n",
      "90, w: 0.577, loss: 15.295254\n",
      "91, w: 0.672, loss: 18.882130\n",
      "92, w: 0.990, loss: 16.435711\n",
      "93, w: 1.476, loss: 9.522038\n",
      "94, w: 2.050, loss: 2.566782\n",
      "95, w: 2.615, loss: 0.022234\n",
      "96, w: 3.078, loss: 3.517244\n",
      "97, w: 3.362, loss: 10.814541\n",
      "98, w: 3.417, loss: 17.242874\n",
      "99, w: 3.237, loss: 18.687263\n",
      "16.600801467895508\n"
     ]
    }
   ],
   "source": [
    "print(model(X_test).item())\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # predict\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # calculate loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradient descent => backward pass in pytorch\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    [w, b] = model.parameters()\n",
    "    print(f\"{_}, w: {w[0][0].item():.3f}, loss: {l:5f}\")\n",
    "\n",
    "print(model(X_test).item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "tensor([2., 4., 6., 8.])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "print(X)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss(y, y_pred):\n",
    "    return  ((y - y_pred)**2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., requires_grad=True) 0.01 50\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "alpha = 0.01\n",
    "iterations = 50\n",
    "print(w, alpha, iterations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MulBackward0>)\n",
      "0, w: 0.300, loss: 30.000000\n",
      "1, w: 0.555, loss: 21.674999\n",
      "2, w: 0.772, loss: 15.660188\n",
      "3, w: 0.956, loss: 11.314487\n",
      "4, w: 1.113, loss: 8.174717\n",
      "5, w: 1.246, loss: 5.906232\n",
      "6, w: 1.359, loss: 4.267253\n",
      "7, w: 1.455, loss: 3.083090\n",
      "8, w: 1.537, loss: 2.227532\n",
      "9, w: 1.606, loss: 1.609392\n",
      "10, w: 1.665, loss: 1.162786\n",
      "11, w: 1.716, loss: 0.840112\n",
      "12, w: 1.758, loss: 0.606981\n",
      "13, w: 1.794, loss: 0.438544\n",
      "14, w: 1.825, loss: 0.316848\n",
      "15, w: 1.851, loss: 0.228923\n",
      "16, w: 1.874, loss: 0.165397\n",
      "17, w: 1.893, loss: 0.119499\n",
      "18, w: 1.909, loss: 0.086338\n",
      "19, w: 1.922, loss: 0.062379\n",
      "20, w: 1.934, loss: 0.045069\n",
      "21, w: 1.944, loss: 0.032562\n",
      "22, w: 1.952, loss: 0.023526\n",
      "23, w: 1.960, loss: 0.016998\n",
      "24, w: 1.966, loss: 0.012281\n",
      "25, w: 1.971, loss: 0.008873\n",
      "26, w: 1.975, loss: 0.006411\n",
      "27, w: 1.979, loss: 0.004632\n",
      "28, w: 1.982, loss: 0.003346\n",
      "29, w: 1.985, loss: 0.002418\n",
      "30, w: 1.987, loss: 0.001747\n",
      "31, w: 1.989, loss: 0.001262\n",
      "32, w: 1.991, loss: 0.000912\n",
      "33, w: 1.992, loss: 0.000659\n",
      "34, w: 1.993, loss: 0.000476\n",
      "35, w: 1.994, loss: 0.000344\n",
      "36, w: 1.995, loss: 0.000248\n",
      "37, w: 1.996, loss: 0.000180\n",
      "38, w: 1.996, loss: 0.000130\n",
      "39, w: 1.997, loss: 0.000094\n",
      "40, w: 1.997, loss: 0.000068\n",
      "41, w: 1.998, loss: 0.000049\n",
      "42, w: 1.998, loss: 0.000035\n",
      "43, w: 1.998, loss: 0.000026\n",
      "44, w: 1.999, loss: 0.000018\n",
      "45, w: 1.999, loss: 0.000013\n",
      "46, w: 1.999, loss: 0.000010\n",
      "47, w: 1.999, loss: 0.000007\n",
      "48, w: 1.999, loss: 0.000005\n",
      "49, w: 1.999, loss: 0.000004\n",
      "tensor(9.9970, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(forward(5))\n",
    "\n",
    "for _ in range(iterations):\n",
    "    # predict\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # calculate loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradient descent => backward pass in pytorch\n",
    "    l.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= alpha * w.grad\n",
    "\n",
    "    # reset gradients\n",
    "    w.grad.zero_()\n",
    "    print(f\"{_}, w: {w:.3f}, loss: {l:5f}\")\n",
    "\n",
    "print(forward(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
